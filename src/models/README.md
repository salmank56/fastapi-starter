# AI Procurement System - Database Schema

## üìã Overview

This is a **production-ready, enterprise-grade** database schema for an AI-powered procurement platform using **FastAPI, SQLAlchemy, LangGraph, and RAG (Retrieval-Augmented Generation)**.

### Core Features
- ‚úÖ **Multi-tenant SaaS** architecture
- ‚úÖ **Event-driven** agent workflow tracking
- ‚úÖ **RAG integration** with Pinecone vector database
- ‚úÖ **AI negotiation** agent with email threading
- ‚úÖ **Audit trail** for compliance
- ‚úÖ **Usage tracking** for billing
- ‚úÖ **Flexible product specs** using JSONB

---

## üóÇÔ∏è Schema Organization

### **1. Core Tenancy** (`organization.py`, `auth.py`)
**Purpose:** Multi-tenant B2B SaaS foundation

#### `Organization`
- Each company/team gets its own organization
- Tracks subscription tier (`free`, `pro`, `enterprise`)
- Links to users, settings, and all activities

#### `OrganizationSettings`
- **Critical:** Stores encrypted API keys (OpenAI, Pinecone, Gmail)
- Usage quotas to prevent runaway costs
- Agent behavior configuration (timeouts, retries, auto-negotiation)

#### `User`
- Full RBAC support: `super_admin`, `org_admin`, `manager`, `member`, `viewer`
- Security features: failed login tracking, account locking
- Email verification and password history

#### `RefreshToken`
- JWT refresh token management
- Supports token revocation and rotation
- Device tracking for security

#### `APIKey`
- Programmatic API access
- Scoped permissions (`search:read`, `products:write`)
- Rate limiting and usage tracking

---

### **2. Agent Workflow** (`agent.py`)
**Purpose:** LangGraph orchestration state management

#### `SearchJob`
- Represents a user query: *"Find MacBook Pro M3 under $2000"*
- Tracks status: `PENDING` ‚Üí `RUNNING` ‚Üí `COMPLETED`/`FAILED`
- Stores cost estimates and actual costs (OpenAI API usage)
- Progress tracking for real-time UI updates

#### `AgentLog`
- The **"Terminal View"** backend
- Logs every agent action: `"ScraperAgent: Taking screenshot..."`
- Frontend polls this table for live agent activity
- Stores step duration for performance analysis

---

### **3. Product Data** (`product.py`)
**Purpose:** Scraped e-commerce data with RAG support

#### `Vendor`
- E-commerce platforms: Amazon, Best Buy, Newegg
- Contact info for negotiator agent
- Scraper configuration per vendor

#### `Product`
- **JSONB `specs` column:** Flexible schema-less product specifications
  - Laptop: `{"ram": "16GB", "processor": "M3"}`
  - Chair: `{"material": "Mesh", "weight_capacity": "300lbs"}`
- **`vector_id`:** Links to Pinecone for semantic search
- **`screenshot_url`:** Evidence from Playwright scraper
- **`price_history`:** Time-series data for trend analysis
- **`confidence_score`:** GPT-4o extraction confidence

#### `MediaFile`
- Centralized file storage (S3/local)
- Supports screenshots, PDFs, exports
- Polymorphic linking to any entity

---

### **4. Negotiation & Procurement** (`negotiation.py`)
**Purpose:** AI negotiator agent workflows

#### `Negotiation`
- Tracks email conversations with vendors
- State machine: `DRAFT` ‚Üí `SENT` ‚Üí `VENDOR_REPLIED` ‚Üí `ACCEPTED`
- **Gmail integration:** `email_thread_id` for conversation threading
- **Human-in-the-loop:** Requires approval before sending money-related emails
- Auto-follow-up scheduling

#### `PurchaseOrder`
- Final output for human approval
- Generates unique PO numbers: `PO-2025-001`
- PDF generation support
- Approval workflow tracking

#### `EmailTemplate`
- Prompt templates for the negotiator agent
- Jinja2 variable support: `{{product_name}}`, `{{target_price}}`
- Track template success rates

---

### **5. Real-Time Features** (`notification.py`)
**Purpose:** User notifications and external webhooks

#### `Notification`
- User-facing alerts: "Job completed", "Vendor replied"
- Deep links to frontend: `/jobs/abc-123`
- Read/unread tracking
- Priority levels: `low`, `normal`, `high`, `urgent`

#### `WebhookEvent`
- Incoming webhooks from Gmail/SendGrid/Stripe
- Idempotency via `external_id`
- Processing status and error tracking
- Auto-match to negotiations

---

### **6. Compliance & Billing** (`audit.py`)
**Purpose:** Audit trails and cost attribution

#### `AuditLog`
- Every critical action logged
- Before/after state for rollback
- IP address and user agent tracking
- Request tracing via `request_id`

#### `UsageLog`
- Granular resource tracking:
  - OpenAI API calls (tokens, cost)
  - Pinecone queries
  - Scraping jobs
- Per-organization cost attribution
- Billing period aggregation (`2025-12`)

---

### **7. User Experience** (`user_features.py`)
**Purpose:** Personalization and productivity

#### `UserPreferences`
- Notification settings
- Theme, language, timezone
- Default search preferences

#### `SearchTemplate`
- Reusable query templates: *"Monthly Laptop Purchase"*
- Variable support for form generation
- Share templates across organization

#### `ComparisonSet`
- Save product comparisons
- Side-by-side analysis
- Track final decision

---

## üîê Security Considerations

### API Key Encryption
**CRITICAL:** The `OrganizationSettings` table stores sensitive API keys. You MUST encrypt these at rest.

**Recommended approach:**
```python
from cryptography.fernet import Fernet

# Store this key in environment variables, NOT in the database
ENCRYPTION_KEY = os.getenv("ENCRYPTION_KEY")
cipher = Fernet(ENCRYPTION_KEY)

# Encrypt before saving
encrypted = cipher.encrypt(api_key.encode()).decode()
org_settings.openai_api_key_encrypted = encrypted

# Decrypt when reading
decrypted = cipher.decrypt(org_settings.openai_api_key_encrypted.encode()).decode()
```

---

## üöÄ Getting Started

### Generate Migration
```bash
# Activate your virtual environment
source venv/bin/activate

# Create new migration
alembic revision --autogenerate -m "Create full AI procurement schema"

# Review the generated migration file in alembic/versions/

# Apply migration
alembic upgrade head
```

### Verify Tables
```bash
# Connect to PostgreSQL
psql -U your_user -d your_db

# List all tables
\dt

# Describe a table
\d+ search_jobs
```

---

## üìä Key Design Patterns

### 1. **JSONB for Flexibility**
```sql
-- Query products by RAM size
SELECT * FROM products 
WHERE specs->>'ram' = '16GB';

-- Index for performance
CREATE INDEX idx_product_specs_ram ON products ((specs->>'ram'));
```

### 2. **Polymorphic Relationships**
```python
# MediaFile can link to any entity
media_file.related_entity_type = "product"
media_file.related_entity_id = product.id
```

### 3. **Composite Indexes**
```python
# Fast billing queries
Index("ix_usage_org_period", "organization_id", "billing_period")
```

### 4. **Time-Series Data**
```python
# Price history stored as JSONB array
product.price_history = [
    {"price": 1999, "timestamp": "2025-12-15T10:00:00Z"},
    {"price": 1899, "timestamp": "2025-12-16T10:00:00Z"}
]
```

---

## üéì Why This Schema is "Senior Level"

1. **Separation of Concerns:** Models organized by domain, not dumped into one file
2. **Type Safety:** Enums for state machines prevent invalid states
3. **Audit Trail:** Every critical action is logged for compliance
4. **Cost Tracking:** Granular usage logs enable accurate billing
5. **RAG Architecture:** Clean separation of operational DB (Postgres) and semantic DB (Pinecone)
6. **Human-in-the-Loop:** AI agents never autonomously spend money
7. **Flexible Schema:** JSONB allows different product types without schema migrations
8. **Idempotency:** Webhooks tracked by `external_id` to prevent duplicate processing

---

## üìö Next Steps

1. **Implement encryption utilities** for `OrganizationSettings`
2. **Create Pydantic schemas** in `src/schemas/` for request/response validation
3. **Build repository layer** in `src/repositories/` for data access
4. **Implement services** in `src/services/` for business logic
5. **Set up Celery** for async job processing
6. **Configure Redis** for job queue

---

## ü§ù Contributing

When adding new models:
1. Place in appropriate domain file
2. Update `src/models/__init__.py`
3. Add enums to `enums.py`
4. Generate migration: `alembic revision --autogenerate`
5. Update this README

---

## üìù Schema Stats

- **18 Tables** across 7 domain modules
- **8 Enums** for type safety
- **UUID primary keys** (except auto-increment logs)
- **Comprehensive indexes** on foreign keys and query-heavy columns
- **JSONB columns** for flexible data storage
- **Timestamp tracking** on all tables

**Total LOC:** ~1,200 lines of production-ready SQLAlchemy models üöÄ

